# -*- coding: utf-8 -*-
"""ModelTraining_and_Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ya_aX0I5hrSGbpNUOSWgHwJysZHmOUJ1

Evaluate the Model: After training, I can evaluated the model's performance by predicting future stock prices.
"""

# Make predictions
predictions = model.predict(X)

# Reshape predictions to have the same number of features as the original data
predictions = predictions.reshape(-1, 1)
predictions = np.repeat(predictions, adj_close.shape[1], axis=1) # Repeat for each feature

# Reverse scaling to get actual prices
predictions_rescaled = scaler.inverse_transform(predictions)

# Example: Print the first 5 predictions
print(predictions_rescaled[:5])

"""Visualize the Results: I visualized the predicted vs actual prices to assess the performance of the LSTM model. As the model didn't involved any sentiment analysis, the prediction is nearly accurrate and the Stock price I have taken is from 1-1-2018 to 1-1-2023"""

import matplotlib.pyplot as plt

# Plot the results for the first stock (AAPL)
actual_prices = scaler.inverse_transform(scaled_data[time_step+1:])

plt.figure(figsize=(10, 6))
plt.plot(actual_prices[:, 0], label='Actual Prices')
plt.plot(predictions_rescaled[:, 0], label='Predicted Prices')
plt.title('NASDAQ-100 Stock Prediction (AAPL)')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

"""Evaluating Multiple Stocks: We want to predict stock price movements for multiple stocks, I used the following approach:

Train separate models for each stock or create a multi-output model that predicts prices for each stock simultaneously.
Use a similar process for each stock, but ensure that the data is normalized and processed separately for each one.
"""

# Train the LSTM model for each stock individually
for symbol in nasdaq_100_symbols:
    stock_data = adj_close[symbol].values
    stock_scaled = scaler.fit_transform(stock_data.reshape(-1, 1))

    X_stock, y_stock = create_dataset(stock_scaled, time_step)
    X_stock = np.reshape(X_stock, (X_stock.shape[0], X_stock.shape[1], 1))

    model = Sequential()
    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_stock.shape[1], X_stock.shape[2])))
    model.add(Dropout(0.2))
    model.add(LSTM(units=50, return_sequences=False))
    model.add(Dropout(0.2))
    model.add(Dense(units=1))

    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(X_stock, y_stock, epochs=20, batch_size=32)

    # Make predictions
    predictions_stock = model.predict(X_stock)
    predictions_rescaled_stock = scaler.inverse_transform(predictions_stock)

    # Plot results for the stock (Example: AAPL)
    plt.figure(figsize=(10, 6))
    plt.plot(stock_data[time_step:], label='Actual Prices')
    plt.plot(predictions_rescaled_stock, label='Predicted Prices')
    plt.title(f'{symbol} Stock Price Prediction')
    plt.xlabel('Time')
    plt.ylabel('Stock Price')
    plt.legend()
    plt.show()

"""Model Training and Evaluation

Now that we've tuned the LSTM model with hyperparameters, the next step is to proceed with the training of the model using the best-found hyperparameters.
"""

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Function to train the LSTM model using the best hyperparameters
def train_lstm_model(stock_symbol, num_posts=10, n_splits=5):
    # Prepare the data
    # The prepare_data_for_lstm function returns 5 values, so you need to unpack them accordingly
    X_train, X_test, y_train, y_test, scaler = prepare_data_for_lstm(stock_symbol, num_posts)

    # Concatenate train and test data for a single X and y
    X = np.concatenate([X_train, X_test])
    y = np.concatenate([y_train, y_test])

    # Split data into training and testing
    X_train, X_test, y_train, y_test = X[:int(0.8*len(X))], X[int(0.8*len(X)):], y[:int(0.8*len(y))], y[int(0.8*len(y)):]

    # Initialize the best model from the previous tuning
    # Assuming cross_validate_lstm now returns best_model, best_hp
    best_model, _ = cross_validate_lstm(stock_symbol, num_posts, n_splits) # Changed to call cross_validate_lstm

    # Train the model with the training data
    history = best_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

    # Model evaluation
    y_pred = best_model.predict(X_test)

    # Calculate evaluation metrics
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"Evaluation Metrics for {stock_symbol}:")
    print(f"Mean Squared Error (MSE): {mse}")
    print(f"Mean Absolute Error (MAE): {mae}")
    print(f"R2 Score: {r2}")

    # Visualizing the prediction vs actual data
    plt.figure(figsize=(10, 6))
    plt.plot(y_test, color='blue', label='Actual Stock Prices')
    plt.plot(y_pred, color='red', label='Predicted Stock Prices')
    plt.title(f"{stock_symbol} Stock Price Prediction vs Actual")
    plt.xlabel("Time")
    plt.ylabel("Stock Price")
    plt.legend()
    plt.show()

    return best_model, history

# Example usage for training and evaluating the model for AAPL stock
best_model, history = train_lstm_model('AAPL', num_posts=10, n_splits=5)

"""Model Training and Evaluation for GOOGLE Stocks"""

def train_lstm_model(stock_symbol, num_posts=10, n_splits=5):
    # Prepare the data

    X_train, X_test, y_train, y_test, scaler = prepare_data_for_lstm(stock_symbol, num_posts)

    # Concatenate train and test data for a single X and y
    X = np.concatenate([X_train, X_test])
    y = np.concatenate([y_train, y_test])

    # Split data into training and testing
    X_train, X_test, y_train, y_test = X[:int(0.8*len(X))], X[int(0.8*len(X)):], y[:int(0.8*len(y))], y[int(0.8*len(y)):]

    # Initialize the best model from the previous tuning

    best_model, _ = cross_validate_lstm(stock_symbol, num_posts, n_splits) # Changed to call cross_validate_lstm

    # Train the model with the training data
    history = best_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

    # Model evaluation
    y_pred = best_model.predict(X_test)

    # Calculate evaluation metrics
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"Evaluation Metrics for {stock_symbol}:")
    print(f"Mean Squared Error (MSE): {mse}")
    print(f"Mean Absolute Error (MAE): {mae}")
    print(f"R2 Score: {r2}")

    # Visualizing the prediction vs actual data
    plt.figure(figsize=(10, 6))
    plt.plot(y_test, color='blue', label='Actual Stock Prices')
    plt.plot(y_pred, color='red', label='Predicted Stock Prices')
    plt.title(f"{stock_symbol} Stock Price Prediction vs Actual")
    plt.xlabel("Time")
    plt.ylabel("Stock Price")
    plt.legend()
    plt.show()

    return best_model, history

# Example usage for training and evaluating the model for AAPL stock
best_model, history = train_lstm_model('GOOG', num_posts=10, n_splits=5)