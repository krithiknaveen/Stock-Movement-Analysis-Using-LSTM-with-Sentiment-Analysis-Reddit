# -*- coding: utf-8 -*-
"""scrape_reddit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YlGPcxuE1imeWsLuhHTYuS0ENkNuR-R0

Fetch NASDAQ-100 Stock Data: Using yfinance to download stock data for the NASDAQ-100 stocks.
"""

import yfinance as yf
import pandas as pd
from zoneinfo import ZoneInfo

# List of NASDAQ-100 companies
nasdaq_100_symbols = ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'TSLA', 'META', 'NVDA', 'INTC', 'CSCO', 'AMD', 'PYPL', 'NFLX']

# Download stock data
stocks_data = yf.download(nasdaq_100_symbols, start='2018-01-01', end='2023-01-01', prepost=True, threads=True)

# Convert the index to the desired timezone
stocks_data.index = stocks_data.index.tz_localize('UTC').tz_convert(ZoneInfo('Asia/Kolkata'))

# Continue with your analysis as before
adj_close = stocks_data['Adj Close']
adj_close.to_csv('nasdaq_100_stocks.csv')

"""RapidAPI's Reddit Scraper to gather data and perform sentiment analysis"""

import requests
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import json

# RapidAPI credentials for Reddit Scraper
api_key = '4e0d6d9ce4msh3bc59dc2526XXXXXXXX0256jsn5653165127f2'
url = "https://reddit-scraper2.p.rapidapi.com/search_posts"

headers = {
    'x-rapidapi-host': "reddit-scraper2.p.rapidapi.com",
    'x-rapidapi-key': api_key
}

# Initialize sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to fetch Reddit posts from RapidAPI
def fetch_reddit_posts(stock_symbol, num_posts=10):
    querystring = {"query": stock_symbol, "limit": num_posts}

    response = requests.get(url, headers=headers, params=querystring)

    if response.status_code == 200:
        data = response.json()
        # Debugging: print the response
        print(f"Response for {stock_symbol}: {json.dumps(data, indent=4)}")

        if "data" in data:
            return data["data"]  # Return the list of posts
        else:
            print(f"No data found for {stock_symbol}.")
            return []
    else:
        print(f"Failed to fetch data for {stock_symbol}. Status Code: {response.status_code}")
        return []

# Function to analyze sentiment of Reddit posts
def analyze_sentiment_from_reddit(stock_symbol, num_posts=10):
    posts = fetch_reddit_posts(stock_symbol, num_posts)

    if not posts:
        return 0  # No posts, return neutral sentiment

    sentiments = []

    for post in posts:
        title = post.get('title', '')
        print(f"Analyzing post: {title}")

        # Get sentiment score of the post title
        sentiment_score = analyzer.polarity_scores(title)['compound']
        sentiments.append(sentiment_score)

    return sum(sentiments) / len(sentiments) if sentiments else 0

# Example usage for AAPL
average_sentiment = analyze_sentiment_from_reddit('AAPL', num_posts=10)
print(f"Average sentiment for AAPL: {average_sentiment}")

"""Using RapidAPI's Reddit Scraper to gather data for other stock such as Google and Microsoft."""

import requests
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import json

# RapidAPI credentials for Reddit Scraper
api_key = '64f9f0a84dmsh37f26582e1157XXXXXXXXXXXX8fjsn4c55d1a408c1'
url = "https://reddit-scraper2.p.rapidapi.com/search_posts"

headers = {
    'x-rapidapi-host': "reddit-scraper2.p.rapidapi.com",
    'x-rapidapi-key': api_key
}

# Initialize sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to fetch Reddit posts from RapidAPI
def fetch_reddit_posts(stock_symbol, num_posts=10):
    querystring = {"query": stock_symbol, "limit": num_posts}

    response = requests.get(url, headers=headers, params=querystring)

    if response.status_code == 200:
        data = response.json()
        # Debugging: print the response
        print(f"Response for {stock_symbol}: {json.dumps(data, indent=4)}")

        if "data" in data:
            return data["data"]  # Return the list of posts
        else:
            print(f"No data found for {stock_symbol}.")
            return []
    else:
        print(f"Failed to fetch data for {stock_symbol}. Status Code: {response.status_code}")
        return []

# Function to analyze sentiment of Reddit posts
def analyze_sentiment_from_reddit(stock_symbol, num_posts=10):
    posts = fetch_reddit_posts(stock_symbol, num_posts)

    if not posts:
        return 0  # No posts, return neutral sentiment

    sentiments = []

    for post in posts:
        title = post.get('title', '')
        print(f"Analyzing post: {title}")

        # Get sentiment score of the post title
        sentiment_score = analyzer.polarity_scores(title)['compound']
        sentiments.append(sentiment_score)

    return sum(sentiments) / len(sentiments) if sentiments else 0

# Example usage for AAPL
average_sentiment_Google = analyze_sentiment_from_reddit('GOOG', num_posts=10)
print(f"Average sentiment for GOOG: {average_sentiment_Google}")

average_sentiment_Microsoft = analyze_sentiment_from_reddit('MSFT', num_posts=10)
print(f"Average sentiment for MSFT: {average_sentiment_Microsoft}")