# -*- coding: utf-8 -*-
"""HyperparameterTuning_and_CrossValidation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E7b9HtlNLYPpGDUYkZEhLsUce_rR3ehu

**Hyperparameter Tuning for AAPL**
"""

import numpy as np
import pandas as pd
import requests
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# RapidAPI credentials for Reddit Scraper
api_key = '4e0d6d9ce4msh3bc59dXXXXXXXX7ep170256jsn5653165127f2'
url = "https://reddit-scraper2.p.rapidapi.com/search_posts"
headers = {
    'x-rapidapi-host': "reddit-scraper2.p.rapidapi.com",
    'x-rapidapi-key': api_key
}

# Initialize sentiment analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to fetch Reddit posts from RapidAPI
def fetch_reddit_posts(stock_symbol, num_posts=10):
    querystring = {"query": stock_symbol, "limit": num_posts}
    response = requests.get(url, headers=headers, params=querystring)
    if response.status_code == 200:
        data = response.json()
        if "data" in data:
            return data["data"]  # Return the list of posts
        else:
            return []
    else:
        return []

# Function to analyze sentiment of Reddit posts
def analyze_sentiment_from_reddit(stock_symbol, num_posts=10):
    posts = fetch_reddit_posts(stock_symbol, num_posts)
    if not posts:
        return 0  # No posts, return neutral sentiment

    sentiments = []
    for post in posts:
        title = post.get('title', '')
        sentiment_score = analyzer.polarity_scores(title)['compound']
        sentiments.append(sentiment_score)

    return sum(sentiments) / len(sentiments) if sentiments else 0

# Function to fetch historical stock data (Yahoo Finance)
def fetch_stock_data(stock_symbol, start_date='2022-01-01', end_date='2024-01-01'):
    import yfinance as yf
    stock_data = yf.download(stock_symbol, start=start_date, end=end_date)
    return stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]

# Function to prepare data for LSTM model
def prepare_data_for_lstm(stock_symbol, num_posts=10):
    # Fetch stock price data
    stock_data = fetch_stock_data(stock_symbol)

    # Add sentiment data
    stock_data['Sentiment'] = stock_data.index.map(lambda x: analyze_sentiment_from_reddit(stock_symbol, num_posts))

    # Drop missing values (if any)
    stock_data.dropna(inplace=True)

    # Normalize the data
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(stock_data[['Open', 'High', 'Low', 'Close', 'Volume', 'Sentiment']])

    # Prepare sequences for LSTM
    X, y = [], []
    for i in range(60, len(scaled_data)):
        X.append(scaled_data[i-60:i])  # Last 60 days of data
        y.append(scaled_data[i, 3])    # Predict the 'Close' price

    X = np.array(X)
    y = np.array(y)

    # Split data into training and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    return X_train, X_test, y_train, y_test, scaler

# Build and compile LSTM model
def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))
    model.add(LSTM(units=50, return_sequences=False))
    model.add(Dense(units=1))  # Predicting the 'Close' price
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Train the model
def train_and_evaluate_model(stock_symbol, num_posts=10):
    # Prepare the data
    X_train, X_test, y_train, y_test, scaler = prepare_data_for_lstm(stock_symbol, num_posts)

    # Build the model
    model = build_lstm_model(X_train.shape[1:])

    # Train the model
    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

    # Evaluate the model
    test_loss = model.evaluate(X_test, y_test)
    print(f"Test Loss (MSE): {test_loss}")

    return model, scaler

# Example usage for AAPL (Apple Inc.)
model, scaler = train_and_evaluate_model('AAPL', num_posts=10)

"""**Cross Validation**"""

import numpy as np
import pandas as pd
import requests
import yfinance as yf
import matplotlib.pyplot as plt
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, TimeSeriesSplit # Import TimeSeriesSplit
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
!pip install TA-Lib
import talib as ta  # Technical Analysis library for indicators
from sklearn.metrics import mean_squared_error  # Import mean_squared_error


def cross_validate_lstm(stock_symbol, num_posts=10, n_splits=5):
    # Prepare the data
    X_train, X_test, y_train, y_test, scaler = prepare_data_for_lstm(stock_symbol, num_posts)

    # TimeSeriesSplit for cross-validation
    tscv = TimeSeriesSplit(n_splits=n_splits)
    X = np.concatenate([X_train, X_test])
    y = np.concatenate([y_train, y_test])


    mse_scores = []  # Store Mean Squared Error for each fold
    for train_index, test_index in tscv.split(X):
        # Split the data into training and testing sets for this fold
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        # Build and train the model
        model = build_lstm_model(X_train.shape[1:])
        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)

        # Make predictions and calculate MSE
        predictions = model.predict(X_test)
        mse = mean_squared_error(y_test, predictions)
        mse_scores.append(mse)

    # Calculate average MSE across all folds
    avg_mse = np.mean(mse_scores)
    print(f"Average MSE across {n_splits} folds: {avg_mse}")

    return avg_mse

# Example usage for AAPL (Apple Inc.)
avg_mse = cross_validate_lstm('AAPL', num_posts=10, n_splits=5)
print(f"Cross-Validation MSE: {avg_mse}")

"""**Cross Validation for GOOG**"""

def cross_validate_lstm(stock_symbol, num_posts=10, n_splits=5):
    # Prepare the data
    X_train, X_test, y_train, y_test, scaler = prepare_data_for_lstm(stock_symbol, num_posts)

    # TimeSeriesSplit for cross-validation
    tscv = TimeSeriesSplit(n_splits=n_splits)
    X = np.concatenate([X_train, X_test])
    y = np.concatenate([y_train, y_test])


    mse_scores = []  # Store Mean Squared Error for each fold
    for train_index, test_index in tscv.split(X):
        # Split the data into training and testing sets for this fold
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        # Build and train the model
        model = build_lstm_model(X_train.shape[1:])
        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)

        # Make predictions and calculate MSE
        predictions = model.predict(X_test)
        mse = mean_squared_error(y_test, predictions)
        mse_scores.append(mse)

    # Calculate average MSE across all folds
    avg_mse = np.mean(mse_scores)
    print(f"Average MSE across {n_splits} folds: {avg_mse}")

    return avg_mse

# Example usage for AAPL (Apple Inc.)
avg_mse = cross_validate_lstm('GOOG', num_posts=10, n_splits=5)
print(f"Cross-Validation MSE: {avg_mse}")

"""Hyperparameter Tuning Using Keras Tuner"""

def build_tuned_lstm_model(hp, input_shape): # Added input_shape as argument
    model = Sequential()

    # Add LSTM layers with tunable hyperparameters
    model.add(LSTM(units=hp.Int('units_1', min_value=50, max_value=200, step=50),
                   return_sequences=True, input_shape=input_shape)) # Use input_shape argument
    model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))

    model.add(LSTM(units=hp.Int('units_2', min_value=50, max_value=200, step=50),
                   return_sequences=False))
    model.add(Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))

    # Output layer
    model.add(Dense(units=1))

    # Compile the model with a tunable learning rate
    model.compile(
        optimizer=tf.keras.optimizers.Adam( # Changed to tf.keras.optimizers
            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')
        ),
        loss='mean_squared_error'
    )

    return model

# Hyperparameter tuning using Keras Tuner
def cross_validate_lstm(stock_symbol, num_posts=10, n_splits=5):
    # Prepare the data
    X_train, X_test, y_train, y_test, scaler = prepare_data_for_lstm(stock_symbol, num_posts)
    X = np.concatenate([X_train, X_test])
    y = np.concatenate([y_train, y_test])

    # Split data into training and testing
    X_train, X_test, y_train, y_test = X[:int(0.8*len(X))], X[int(0.8*len(X)):], y[:int(0.8*len(y))], y[int(0.8*len(y)):]

    # Get input shape for the model
    input_shape = (X_train.shape[1], X_train.shape[2])

    # Initialize the Keras Tuner
    tuner = kt.Hyperband(
        lambda hp: build_tuned_lstm_model(hp, input_shape), # Pass input_shape to build_tuned_lstm_model
        objective='val_loss',  # Minimize validation loss
        max_epochs=10,
        factor=3,
        directory='hyperparameter_tuning',
        project_name='lstm_stock_tuning_Google'
    )

    # Search for the best hyperparameters
    tuner.search(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

    # Get the best model and hyperparameters
    best_model = tuner.get_best_models(num_models=1)[0]
    # Use get_best_hyperparameters instead of get_best_trials
    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]

    # Print the best hyperparameters
    print("Best Hyperparameters:", best_hp.values)

    return best_model, best_hp
best_model, best_hp = cross_validate_lstm('GOOG', num_posts=10, n_splits=5) # Changed this line

# Prepare the data to get X_test and y_test
X_train, X_test, y_train, y_test, scaler = prepare_data_for_lstm('GOOG', num_posts=10)
X = np.concatenate([X_train, X_test])
y = np.concatenate([y_train, y_test])

# Split data into training and testing to get X_test and y_test for evaluation
X_train, X_test, y_train, y_test = X[:int(0.8*len(X))], X[int(0.8*len(X)):], y[:int(0.8*len(y))], y[int(0.8*len(y)):]

# Evaluate the best model using the X_test and y_test defined above
loss = best_model.evaluate(X_test, y_test)
print(f"Best model loss: {loss}")

"""MSE for GOOG"""

modelGoogle, scalerGoogle = train_and_evaluate_model('GOOG', num_posts=10)
modelMicrosoft, scalerMicrosoft = train_and_evaluate_model('MSFT', num_posts=10)